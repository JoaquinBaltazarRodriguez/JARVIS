"use client"

import { useState, useEffect } from "react"

// Variable global para controlar el silenciamiento
let isMuted = false;

// Funci√≥n para establecer el estado global de silencio
export function setNexusVoiceMuted(muted: boolean) {
  isMuted = muted;
  console.log(`üîä NEXUS voice ${muted ? 'muted' : 'unmuted'}`);
  // Guardar preferencia en localStorage
  if (typeof localStorage !== 'undefined') {
    localStorage.setItem('nexus_voice_muted', muted ? 'true' : 'false');
  }
}

// Funci√≥n para obtener el estado global de silencio
export function isNexusVoiceMuted(): boolean {
  return isMuted;
}

export function useSimpleAudio() {
  const [isSpeaking, setIsSpeaking] = useState(false)
  const [isReady, setIsReady] = useState(false)
  const [audioContext, setAudioContext] = useState<AudioContext | null>(null)

  useEffect(() => {
    const initializeAudio = () => {
      try {
        // üé§ INICIALIZAR WEB AUDIO API PARA EFECTOS
        const context = new (window.AudioContext || (window as any).webkitAudioContext)()
        setAudioContext(context)

        const voices = speechSynthesis.getVoices()
        console.log("üé§ Available voices:", voices.length)
        if (voices.length > 0) {
          setIsReady(true)
        }
        
        // Cargar preferencia de silenciamiento desde localStorage
        if (typeof localStorage !== 'undefined') {
          const savedMuted = localStorage.getItem('nexus_voice_muted');
          if (savedMuted === 'true') {
            isMuted = true;
            console.log('üîä NEXUS voice loaded as muted from settings');
          }
        }
      } catch (error) {
        console.error("‚ùå Error initializing audio:", error)
      }
    }

    // ‚ö° INICIALIZACI√ìN M√ÅS R√ÅPIDA
    setTimeout(initializeAudio, 200)

    const handleVoicesChanged = () => {
      const voices = speechSynthesis.getVoices()
      console.log("üé§ Voices changed:", voices.length)
      if (voices.length > 0) {
        setIsReady(true)
      }
    }

    speechSynthesis.addEventListener("voiceschanged", handleVoicesChanged)

    return () => {
      speechSynthesis.removeEventListener("voiceschanged", handleVoicesChanged)
    }
  }, [])

  const speak = (text: string) => {
    return new Promise<void>((resolve) => {
      console.log("üó£Ô∏è NEXUS SPEAKING:", text)
      setIsSpeaking(true)
      
      // Si est√° silenciado, solo registrar el texto pero no reproducir audio
      if (isMuted) {
        console.log("üîá NEXUS is muted, skipping speech")
        setTimeout(() => {
          setIsSpeaking(false)
          resolve()
        }, 500) // Simular un peque√±o retraso como si hubiera hablado
        return
      }

      speechSynthesis.cancel()

      // ‚ö° TIEMPO DE ESPERA REDUCIDO PARA RESPUESTA M√ÅS R√ÅPIDA
      setTimeout(() => {
        const utterance = new SpeechSynthesisUtterance(text)
        utterance.lang = "es-ES"
        utterance.rate = 1.2 // üöÄ VELOCIDAD OPTIMIZADA PARA NEXUS
        utterance.pitch = 0.4 // ü§ñ M√ÅS GRAVE PARA EFECTO ROB√ìTICO NEXUS
        utterance.volume = 0.95 // üîä VOLUMEN ALTO

        // üé§ BUSCAR VOZ MASCULINA Y GRAVE PARA NEXUS
        const voices = speechSynthesis.getVoices()
        const nexusVoice = voices.find(
          (voice) =>
            (voice.lang.includes("es") || voice.lang.includes("en")) &&
            (voice.name.toLowerCase().includes("male") ||
              voice.name.toLowerCase().includes("diego") ||
              voice.name.toLowerCase().includes("carlos") ||
              voice.name.toLowerCase().includes("jorge") ||
              voice.name.toLowerCase().includes("daniel") ||
              voice.name.toLowerCase().includes("alex") ||
              voice.name.toLowerCase().includes("david") ||
              voice.name.toLowerCase().includes("microsoft") ||
              voice.name.toLowerCase().includes("google") ||
              voice.name.toLowerCase().includes("enhanced")),
        )

        utterance.rate = 1.4
        utterance.pitch = 0.1
        utterance.volume = 10

        if (nexusVoice) {
          utterance.voice = nexusVoice
          console.log("ü§ñ Using NEXUS-like voice:", nexusVoice.name)
        } else {
          const maleVoice = voices.find((voice) => voice.name.toLowerCase().includes("male"))
          if (maleVoice) {
            utterance.voice = maleVoice
            console.log("ü§ñ Using male voice:", maleVoice.name)
          } else {
            console.log("ü§ñ Using default voice with robotic settings")
          }
        }

        utterance.onend = () => {
          console.log("‚úÖ NEXUS speech completed")
          setIsSpeaking(false)
          resolve()
        }

        utterance.onerror = (event) => {
          console.error("‚ùå NEXUS speech error:", event.error)
          setIsSpeaking(false)
          resolve()
        }

        utterance.onstart = () => {
          console.log("ü§ñ NEXUS voice activated")

          // üéõÔ∏è APLICAR EFECTO ROB√ìTICO AVANZADO
          if (audioContext) {
            try {
              // Crear efectos de audio m√°s rob√≥ticos
              const gainNode = audioContext.createGain()
              const biquadFilter = audioContext.createBiquadFilter()

              // Configurar filtro para sonido m√°s rob√≥tico
              biquadFilter.type = "lowpass"
              biquadFilter.frequency.value = 3000 // Frecuencia m√°s baja para efecto rob√≥tico
              biquadFilter.Q.value = 1.5

              // Configurar ganancia para reverb sutil
              gainNode.gain.value = 0.8

              console.log("üéõÔ∏è Advanced robotic audio effects applied")
            } catch (error) {
              console.log("‚ö†Ô∏è Advanced audio effects not available, using enhanced voice settings")
            }
          }
        }

        speechSynthesis.speak(utterance)
      }, 50) // ‚ö° REDUCIDO PARA RESPUESTA M√ÅS R√ÅPIDA
    })
  }

  return { speak, isSpeaking, isReady }
}
