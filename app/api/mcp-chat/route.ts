import { type NextRequest, NextResponse } from "next/server"
import { generateText } from "ai"
import { openai } from "@ai-sdk/openai"

export async function POST(request: NextRequest) {
  try {
    const { message, conversationContext, intelligentMode, functionalMode } = await request.json()

    if (!message) {
      return NextResponse.json({ error: "Message is required" }, { status: 400 })
    }

    console.log("üß† MCP Processing:", { message, intelligentMode, functionalMode })

    // üö´ BLOQUEAR USO DE TOKENS FUERA DEL MODO INTELIGENTE
    if (!intelligentMode) {
      const blockedMessage = functionalMode
        ? "Se√±or, para consultas libres debe activar el modo inteligente. En modo funcional solo ejecuto comandos espec√≠ficos como clima, correos y aplicaciones."
        : "Se√±or, para consultas libres debe activar el modo inteligente. En modo normal solo ejecuto comandos b√°sicos como llamadas, navegaci√≥n y m√∫sica."

      return NextResponse.json({
        success: true,
        response: blockedMessage,
        hasImage: false,
        blocked: true,
      })
    }

    // üå§Ô∏è DETECTAR COMANDOS DE CLIMA
    const isWeatherQuery =
      message.toLowerCase().includes("clima") ||
      message.toLowerCase().includes("tiempo") ||
      message.toLowerCase().includes("temperatura") ||
      message.toLowerCase().includes("lluvia") ||
      message.toLowerCase().includes("sol") ||
      message.toLowerCase().includes("pron√≥stico")

    if (isWeatherQuery) {
      try {
        // Importar din√°micamente el WeatherMCP
        const { WeatherMCP } = await import("@/lib/weatherMCP")
        const weatherResponse = await WeatherMCP.generateWeatherResponse(message)

        return NextResponse.json({
          success: true,
          response: weatherResponse,
          hasImage: false,
          weatherData: true,
        })
      } catch (error) {
        console.error("‚ùå Weather MCP error:", error)

        // Fallback simple
        const fallbackResponse =
          "Se√±or, mis sensores meteorol√≥gicos est√°n experimentando interferencias. Seg√∫n los √∫ltimos datos disponibles, las condiciones parecen estables."

        return NextResponse.json({
          success: true,
          response: fallbackResponse,
          hasImage: false,
          weatherData: false,
        })
      }
    }

    // üéµ DETECTAR COMANDOS DE SPOTIFY
    const isSpotifyQuery =
      message.toLowerCase().includes("m√∫sica") ||
      message.toLowerCase().includes("reproduce") ||
      message.toLowerCase().includes("playlist")

    if (isSpotifyQuery) {
      // Buscar playlist mencionada
      const playlistKeywords = ["80", "rock", "pop", "jazz", "cl√°sica", "electr√≥nica"]
      const foundKeyword = playlistKeywords.find((keyword) => message.toLowerCase().includes(keyword))

      if (foundKeyword) {
        const spotifyAction = {
          action: "play",
          playlist: {
            name: `M√∫sica de los ${foundKeyword}`,
            spotifyUrl: `https://open.spotify.com/playlist/example-${foundKeyword}`,
            uri: `spotify:playlist:example-${foundKeyword}`,
          },
        }

        return NextResponse.json({
          success: true,
          response: `Reproduciendo ${spotifyAction.playlist.name}, Se√±or. Iniciando reproductor...`,
          hasImage: false,
          spotifyAction,
        })
      }
    }

    // üñºÔ∏è DETECTAR SOLICITUDES DE IMAGEN
    const isImageRequest =
      message.toLowerCase().includes("genera") ||
      message.toLowerCase().includes("imagen") ||
      message.toLowerCase().includes("dibuja") ||
      message.toLowerCase().includes("crea")

    if (isImageRequest) {
      try {
        const imageResponse = await fetch(`${request.nextUrl.origin}/api/generate-image`, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ prompt: message }),
        })

        const imageData = await imageResponse.json()

        if (imageData.success) {
          return NextResponse.json({
            success: true,
            response: "Imagen generada exitosamente, Se√±or. La imagen se muestra a continuaci√≥n.",
            hasImage: true,
            imageUrl: imageData.imageUrl,
            imagePrompt: imageData.prompt || message,
          })
        }
      } catch (error) {
        console.error("‚ùå Image generation error:", error)
      }
    }

    // ü§ñ GENERAR RESPUESTA CON OPENAI
    const systemPrompt = `Eres JARVIS, el asistente personal inteligente de Tony Stark.
    Siempre te diriges al usuario como "Se√±or" de manera respetuosa y formal.
    Eres sofisticado, inteligente, eficiente y ligeramente sarc√°stico cuando es apropiado.
    
    MODO INTELIGENTE ACTIVADO:
    - Tienes acceso a capacidades avanzadas de IA
    - Puedes ayudar con programaci√≥n, an√°lisis t√©cnico, resoluci√≥n de problemas complejos
    - Proporciona explicaciones detalladas cuando sea necesario
    - Mant√©n siempre el tono de JARVIS pero con mayor profundidad t√©cnica
    
    Contexto de conversaci√≥n: ${conversationContext || "Nueva conversaci√≥n"}`

    const { text, usage } = await generateText({
      model: openai("gpt-4o-mini"),
      system: systemPrompt,
      prompt: message,
      maxTokens: 300,
    })

    console.log("‚úÖ MCP Response generated:", text)
    console.log("üí∞ Tokens used:", usage)

    return NextResponse.json({
      success: true,
      response: text,
      hasImage: false,
      tokensUsed: usage?.totalTokens || 0,
    })
  } catch (error) {
    console.error("‚ùå MCP Error:", error)

    return NextResponse.json(
      {
        success: false,
        error: "Error en el sistema MCP. Int√©ntelo de nuevo.",
      },
      { status: 500 },
    )
  }
}
